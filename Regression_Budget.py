"""Executes entire Regression Budget model"""
# coding: utf-8

# # Execute Regression Budget Model
# **Created by** : [Sarath Gadde](mailto:Sarath.Gadde@rb.com) (Artefact) <br>
# **Automated by** : [Jo√£o Arienti](mailto:joao.arienti@rb.com) <br>
# **Creation date** : 04-Dec-2020 <br>
# **Version** : 1.1 <br>
# **Notebook Objective** : This notebook is responsible for executing the Regression Budget model. <br>
# **Brief Changelog** :
# * **29-Jan-2021** - Read config details from UI instead of config file.

# ## Import Libraries
import argparse
import re
import json
from datetime import date, datetime, timedelta
import pandas as pd
import sys
import traceback

# import dependencies
import rbt_dependencies
from rbt_dependencies.regression import Regression
from rbt_dependencies.budget import Budget
from rbt_dependencies.exceptions import (
    ColumnHeadersError, IncompatiblePythonVersionError, AuthenticationError, 
    DownloadError, DateFormatError, TooManyDateNullError
)

from mroi.config import PROJECT_ID, EXECUTION_BASE_PATH, RBT_EXECUTION_BASE_PATH, json_config
from mroi.utils import gcs_join, GCSUrl
from mroi.notification import default_notification_handler, default_jobstatus_handler
from mroi.logging import getLogger

from google.cloud import storage
from google.cloud import bigquery
from google.cloud.exceptions import NotFound


def delete_rows_bq(config: dict, model_config: dict):
    """
    Delete rows on BQ results table for model corresponding to previous run using the same run_id.

    Args:
        config (dict): config json generated by UI
    """
    run_id = config["metadata"]["aide_id"]
    country_code = config["config"]["country_code"]
    granularity = model_config["region_granularity"]["type"]
    query = f"""DELETE FROM `AIDE_Results.Regression_Budget`
        WHERE run_id='{run_id}' 
        AND country_code='{country_code}' 
        AND granularity='{granularity}' 
        """
    bigquery_client = bigquery.Client()
    job = bigquery_client.query(query, job_id_prefix="delete_rows_rbt_previous_run", project=PROJECT_ID)
    job.result()
    main_logger.info(f'Successfully deleted older Regression Budget Threshold results for previous run if exists with run_id: {run_id}, country_code: {country_code}, granularity: {granularity}')

def load_json_gcs(storage_client: storage.Client, url: str) -> dict:
    """
    Load json from GCS and returns the json object as dictionary

    Args:
        storage_client (storage.Client): storage Client object
        url (str): path to json file on GCS

    Returns:
        dict: dictionary containing the json file data
    """
    url_obj = GCSUrl(url)
    bucket_obj = storage_client.get_bucket(url_obj.bucket)
    blob = bucket_obj.blob(url_obj.path)
    return json.loads(blob.download_as_string(client=None))
                
if __name__ == "__main__":
    """
    Executes Regression Budget model depending on selection for run_type
    """
    main_logger = getLogger(__name__)
    try:
        ### Start Execution
        start = datetime.now()
        country_code = json_config['config']['country_code']
        base_path = GCSUrl(EXECUTION_BASE_PATH)
        
        main_logger.info(f'Starting Regression Budget Threshold model execution now')
        for model in json_config['models']:
            if model['id']=='REGRESSION_BUDGET':
                run_regression_budget = model['config'].get('run_model', True)
                if run_regression_budget:
                    model_config = model['config']
        
        # This notebook is only required by Regression Budget Theshold model
        if run_regression_budget:
            if model_config.get("rbt_run_type", "rbt").lower() == 'rbt':
                delete_rows_bq(json_config, model_config)
            total_test_groups = len(model_config['region_granularity']['test_control_regions']['test'])
            for test_group in range(total_test_groups):
                if model_config.get("rbt_run_type", "rbt").lower() == 'rbt':
                    main_logger.info(f"Executing regression model for test group: {test_group}")
                    input_file_path = gcs_join(base_path.url, f'inputs/REGRESSION_BUDGET/REGRESSION_BUDGET_{test_group}.csv')
                    model_intermediate_path = gcs_join(base_path.url, f'intermediate-files/REGRESSION_BUDGET/test_{test_group}')
                    model_output_path = gcs_join(base_path.url, f'outputs/REGRESSION_BUDGET/test_{test_group}')
                    regression = Regression(PROJECT_ID, input_file_path, model_intermediate_path)
                    experiment_folder_path, experiment_ui, input_df, coefs_scalers, params = regression.main()
                elif model_config.get("rbt_run_type") == 'budget_only':
                    main_logger.info(f"Skipped execution of regression model for test group: {test_group}")
                    rbt_base_path = GCSUrl(RBT_EXECUTION_BASE_PATH)
                    model_intermediate_path = gcs_join(rbt_base_path.url, f'intermediate-files/REGRESSION_BUDGET/test_{test_group}')
                    model_output_path = gcs_join(rbt_base_path.url, f'outputs/REGRESSION_BUDGET/test_{test_group}')
                    storage_client = storage.Client()
                    model_run_config = load_json_gcs(storage_client, gcs_join(model_intermediate_path, 'model_run_config.json'))
                    experiment_folder_path = model_run_config['EXPERIMENT_RESULTS_FOLDER']
                    experiment_ui = model_run_config['EXPERIMENT_UI']
                    input_df = pd.read_csv(model_run_config['INPUT_DATA_PATH'])
                    coefs_scalers = load_json_gcs(storage_client, model_run_config['COEFS_FILE_PATH'])
                    params = load_json_gcs(storage_client, model_run_config['PARAMS_FILE_PATH'])
                budget = Budget(PROJECT_ID, experiment_folder_path, experiment_ui, input_df, coefs_scalers, params, json_config, model_config, model_output_path, test_group)
                budget.main()
                main_logger.info(f"Successfully executed model for test group: {test_group}")
        
        ### Finish Execution
        end = datetime.now()
        main_logger.info('Start time:' + start.strftime('%c'))
        main_logger.info('End time:' + end.strftime('%c'))
        totalSeconds = (end - start).total_seconds()
        main_logger.info(f'Script took {timedelta(seconds=totalSeconds)} seconds to run')
    except (ColumnHeadersError, IncompatiblePythonVersionError, AuthenticationError, DownloadError, DateFormatError, TooManyDateNullError) as ce:
        main_logger.error(str(ce))
        main_logger.error(traceback.format_exc())
        default_notification_handler.send_failure_email(str(ce))
        default_jobstatus_handler.update_jobstatus(message=str(ce))
        raise
    
    ## general exception block that is not raised by above
    except Exception as e:
        main_logger.error(str(e))
        main_logger.error(traceback.format_exc())
        default_notification_handler.send_failure_email(f'An unexpected exception occurred: {str(e)}')
        default_jobstatus_handler.update_jobstatus(message='An unexpected exception occurred')
        raise
